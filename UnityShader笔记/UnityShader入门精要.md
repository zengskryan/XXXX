## 第二章 渲染流水线

### 2.1 综述：什么是渲染流水线

[别人的笔记，渲染流水线](https://segmentfault.com/a/1190000020767062)

《Render-Time Rendering》中的渲染流程

1. 应用阶段：由应用主导，通常由CPU负责实现，开发者包含3个主要任务，最重要的输出是渲染所需的几何信息，及**渲染图元（rendering primitives，比如一个三角形）**
   * 准备好场景数据：摄像机位置，视椎体，模型，光源等等。
   * 粗粒度剔除：把不可见的物体剔除出去。
   * 设置模型的渲染状态：使用的材质(漫反射颜色，高光反射颜色等)，纹理，shader等。
2. 几何阶段：处理所有和我们要绘制的几何先关的事情，这一阶段通常在GPU上进行。
   * 负责和每个渲染图元打交道，进行逐顶点，逐多边形的操作。
   * 把顶点坐标变换到屏幕空间。
   * 对输入的渲染图元进行多步处理，最终输出屏幕空间的二维顶点坐标，顶点的深度值，着色等。
3. 光栅化阶段：使用上个阶段传递的数据产生屏幕上的像素，并渲染处最终的图像。
   * 决定每个渲染图元中的哪些像素应该被绘制。
   * 对上一个阶段得到的逐顶点数据(如纹理坐标，顶点颜色等)进行插值，然后在进行逐像素处理。

### 2.2 CPU和GPU之间的通信

**阶段：**渲染流水线的起点是CPU，即应用阶段，大致分为三个小阶段

1. 把数据加载到显存中。渲染所需的数据  硬盘--->系统内存--->显存
2. 设置渲染状态
3. 调用draw call

**渲染状态：**这些状态定义了场景中的网格时怎样被渲染的。比如使用那个顶点着色器，光源属性，材质，纹理等。其实类似于一个对象实例，里面包含了渲染某个网格需要的所有属性。

**调用Draw Call**

1. CPU准备好渲染状态后，就需要调用一个渲染命令来通知GPU渲染。
2. drawcall命令仅仅指向一个需要被渲染的图元列表。不再包含材质信息（因为上面第一步就把数据加载到显存中了）。
3. 给定一个Drawcall后，GPU就会根据渲染状态(例如材质，纹理)和所有输入的顶点数据进行计算，最终输出像素。这个计算过程就是**GPU流水线。**

### 2.3 GPU流水线

定义：GPU得到渲染命令后，将图元渲染到屏幕的一系列流水操作。

流水线阶段：

<img src="UnityShader入门精要.assets/image-20210904205012919.png" alt="image-20210904205012919" style="zoom:70%;" />

<img src="UnityShader入门精要.assets\image-20210715074710235.png" alt="image-20210715074710235" style="zoom: 50%;" />

#### 2.3.2 顶点着色器：几何阶段开始

GPU在每个输入的网格顶点上都会调用顶点着色器。

1. 流水线的第一个阶段。
2. 顶点着色器本身不可以创建或销毁任何顶点，无法得到顶点与顶点之间的关系
3. 顶点相互独立，GPU可以并行处理每一个顶点。
4. 主要工作：坐标变换和逐顶点光照，输出后续阶段所需的数据

坐标变换：

1. 对顶点的坐标进行某种变换。
2. 把顶点坐标从模型空间转换到齐次裁剪空间（NDC，normalized device coordinates，归一化的设备坐标）。
3. 顶点着色器可以在这一步改变顶点的位置，这在顶点动画中非常有用。
4. 通过改变位置可以模拟水面、布料等。

#### 2.3.3 裁剪

用来实现不在摄像机视野范围内的物体不需要传递下去的方式。

一个图元和摄像机视野的关系：

1. 完全在视野内：继续传递给下一个流水线阶段
2. 完全在视野外：直接丢弃，不传递。
3. 部分在视野内：使用裁剪进行处理。在视野外部的顶点使用一个新的顶点，位于内部顶点外部顶点连线与视野边界交点。这部分基于上一步得到的NDC坐标来处理

#### 2.3.4 屏幕映射

输入：仍然是三维坐标系下的坐标（范围在单位立方体内）。

任务：把每个图元的x和y坐标转换到屏幕坐标系(和显示画面的分辨率有很大关系，坐标范围-1到1)下。这个过程实际上是一个缩放过程。

窗口坐标系：屏幕坐标系和z坐标一起构成了一个坐标系。这些值会一起被传递到光栅化阶段。

#### 2.3.5 三角形设置：光栅化开始

**光珊化阶段**任务：1. 计算每个图元覆盖了哪些像素，2. 为这些像素计算它们的颜色。

输入：屏幕坐标系下的顶点位置以及额外信息，如深度值(z坐标)、法线方向、视角方向。

任务也是定义：计算光栅化一个三角网格所需的信息，得到一个三角形网格表示数据的过程。

#### 2.3.6 三角形遍历

定义：也称为扫描变换，主要是检查每个像素是否被一个三角网格所覆盖，如果被覆盖，就会生成一个片元。这个过程叫三角形遍历。

插值：使用三角网格3个顶点的顶点信息对覆盖区域的箱数进行插值。

输出：片元序列。一个片元不是真正意义上的像素，而是包含了很多状态(屏幕坐标，深度信息等)的集合，这些状态用于计算每个像素的最终颜色。

#### 2.3.7 片元着色器

这个阶段可以完成很多重要的渲染技术。其中之一是纹理采样。根据顶点着色器输出的每个顶点对应的纹理坐标，和光栅化(这里应该就是指三角形设置和遍历阶段)对三角网格顶点对应的纹理坐标插值，就可以得到其覆盖的片元的纹理坐标了。

#### 2.3.8 逐片元操作

渲染流水线最后一步，在DirectX中称为输出输出合并阶段。这个阶段不可编程，但可高度配置。

任务：1.经过各种测试，深度，模板测试，决定每个片元的可见性。2.将片元的颜色与缓冲区的进行混合。

模板测试：可以开启或不开启

1. 比较模板缓冲。通过比较来判断是否通过模板测试。比较函数可指定
2. 修改模板缓冲，测试完成后，可以指定修改模板缓冲的操作，比如保持不变或将对应值加1.

深度测试：可以开启或不开启

1. 比较深度缓冲。决定丢弃或保留
2. 片元只有通过深度测试才能修改深度缓冲。

混合（Blend）：可以开启或不开启，只有通过所有测试才能到达这一步

1. 关闭混合：则新的颜色值直接覆盖颜色缓冲区的像素值
2. 开启混合：进行混合（透明效果就需要开启混合）。
3. 混合函数：和透明通道嘻嘻相关，比如根据透明通道的值进行相加，相减，相乘等。

提前测试：

1. Early-z技术：将深度测试提前到片元着色器之前，减少不必要的计算。Unity里面就是
2. 片元着色器的透明度测试与测试提前的冲突  ？？？？

双重缓冲：

1. 避免屏幕显示哪些正在光栅化的图元。
2. 后置缓冲：当前帧渲染过程的缓冲，场景的渲染在幕后发生。
3. 前置缓冲：屏幕用来显示的缓冲。
4. 后置缓冲渲染完毕，GPU就会交换后置缓冲与前置缓冲的内容。





### 2.4 一些容易困惑的地方

#### 2.4.1 OpenGL/DirectX 

1. 这两个都是图像应用编程接口：封装了寄存器，显存等硬件的操作。
2. 这两个实际上都是一个标准，一个规范，定义了一个跨编程语言、跨平台的编程接口的标准，并不是一个API库。
3. ![image-20210717195719446](UnityShader入门精要.assets\image-20210717195719446.png)
4. 参考：[OpenGL底层实现原理](https://blog.csdn.net/qq_23034515/article/details/108132191)
5. 这些接口相当于上层应用程序和底层GPU的桥梁。
6. 显卡驱动：真正知道如何和GPU通信，把OpenGL或DirectX的函数翻译成GPU能够听懂的语言，也负责把纹理等数据转换成GPU所支持的格式。可以理解为显卡的操作系统
7. 应用程序发送命令 --->  图形接口   --->   显卡驱动
8. 一个显卡制作商为了让他们的显卡可以同时和OpenG2L、DirectX合作，就必须提供支持两种接口的显卡驱动。
9. ![image-20210717090659323](UnityShader入门精要.assets\image-20210717090659323.png)

#### 2.4.2 什么是 HLSL、GLSL、CG

都是着色语言，最终都会被编译成与机器无关的会变语言，也被称为中间语言，这些中间语言再交给显卡驱动来翻译成真正的机器语言，即GPU可以理解的语言。

HLSL：DirectX的着色语言，有微软控制着色器的编译，支持HLSL的平台有限，几乎全是微软自己的产品（windows，Xbox 360 、PS3等），因为其他平台没有可以编译HLSL的编译器。

GLSL：OpenGL的着色语言，跨平台，因为OPenGL没有提供着色器编译器，而是由显卡驱动来完成编译。也就是说，只要显卡驱动支持对GLSL的编译他就可以运行。也就是说，GLSL是依赖硬件，而非操作系统层级的。

CG：NVIDIA开发的语言，真正的跨平台，他会根据平台的不同，编译成相应的中间语言。现在已经不在维护。

#### 2.4.3 什么是DrawCall

drawcall就是CPU调用图像编程接口，如OpenGL中的glDrawElements或者DirectX中的DrawIndexedPrimitive命令。

问题1：CPU和GPU是如何实现并行工作的？

1. 命令缓冲区：包含一个命令队列，Cpu添加命令，GPU读取并执行命令。
2. 命令的种类：有很多，DrawCall，改变渲染状态(改变使用的着色器，使用不同的纹理等)等。
3. ![image-20210717204138291](UnityShader入门精要.assets\image-20210717204138291.png)

问题2：为什么DrawCall多个会影响帧率？

1. 拷贝文件举例：拷贝10000个1kb的文件比拷贝1个10MB慢很多，因为拷贝操作本身需要很多额外的性能开销。所以拷贝数量多了，开销将会很大。
2. 每次调用Drawcall之前，CPU需要想GPU发送很多内容，包括数据，状态命令等，CPU需要完成很多工作，而GPU的渲染能力是很强的，所以渲染速度快于cpu提交命令的速度。**GPU处于空闲，帧率降低。所以本质上是CPU在拖后腿。**

问题3：如何减少Draw Call？

1. 方法有很多，这里仅讨论使用批处理。
2. 批处理思想：提交大量很多小的DrawCall会造成CPU性能瓶颈，即CPU把时间都花费在准备DrawCall的工作上了。所以把很多小的DrawCall合并成一个大的DrawCall。
3. 批处理需要在CPU的内存中合并网格，合并过程是需要消耗时间的。所以批处理技术更适用于那些静态的物体，那些物体仅需要合并一次。动态物体也可以，但是每一帧都要重新计算并合并。
4. 游戏开发中，1.避免使用大量很小的网格，不可避免时，考虑合并  2.避免过多的材质，尽量在不同的网格之间公用一个材质，因为相同材质的物体只有顶点数据不同，因此Unity可以合并进行批处理。
5. [Unity动态批处理和静态批处理](https://www.cnblogs.com/MuniuTian/p/10865276.html)

#### 2.4.4 什么是固定管线渲染

1. **固定函数的流水线**，也简称固定管线，通常指在较旧的GPU上实现的渲染流水线。
2. 只提供一些配置操作。可配置的管线，就好像控制电路上的多个开关，我们可以选择打开或者关闭一个开关。
3. 现在固定管线逐渐退出历史舞台，而是使用可编程的管线。

### 2.5 那么你明白什么是Shader了吗

1. Gpu流水线上一些可高度编程的阶段，而由着色器编译出来的最终代码是在GPU上运行的
2. 有一些特定类型的着色器：顶点着色器，片元着色器等。
3. 依靠着色器可以控制流水线中的渲染细节。

## 第3章 Unity Shader基础

### 3.1 概述

#### 3.1.1 材质和shader

1. shader 定义了渲染所需的各种代码（顶点着色器和片元着色器）、属性（如使用了哪些纹理）和指令（渲染和标签设置等）。
2. 材质允许我们调节这些属性，并将其最终赋给相应的模型。

#### 3.1.3 UnityShader

创建Shader

1. Standard Surface Shader：产生一个包含了标准光照模型的表面着色器模板
2. Unlit Shader ：产生一个不包含光照（但包含雾效）的基本的顶点/片元着色器
3. Image Effect Shader：实现各种屏幕后处理效果提供一个模板
4. Compute Shader：产生一种特殊的shader文件，旨在利用GPU的并行性来进行一些与常规渲染流水线无关的计算。

Shader导入面板：进行导入设置

1. Default Maps：可以指定shader使用的默认纹理，任何材质球第一次使用shader时，都会自动关联这个纹理。
2. 一些基本信息：是否是表面着色器等
3. 标签设置相关：是否会投射阴影。使用的渲染队列，lod值等。

### 3.2 ShaderLab

计算机学中的任何问题都可以通过增加一层抽象来解决  ----大卫.惠勒

定义：

1. ShaderLab是Unity为开发者提供的高层及的渲染抽象层。是Unity提供的编写UnityShader的一种说明性语言。

2. ![image-20210718102738865](UnityShader入门精要.assets\image-20210718102738865.png)

3. ShaderLab使用了一些嵌套在花括号内部的语义来描述一个UnityShader文件的结构。包含了许多渲染所需的数据。

4. 基本结构![image-20210718103038344](UnityShader入门精要.assets\image-20210718103038344.png)

   

### 3.3 Unity Shader 的结构

#### 3.3.1 Shader的名字

   在Unity Shader的第一行，用过Shader 语义来指定名字，选择shader使用时就显示这个名字。

![image-20210718103640806](UnityShader入门精要.assets\image-20210718103640806.png)

#### 3.3.2 材质和UnityShader的桥梁：Properties

1. Properties语块中定义了一系列属性，这些属性将会出现在材质面板中
2. 语义块定义：![image-20210718103843519](UnityShader入门精要.assets\image-20210718103843519.png)
3. 属性类型：![image-20210718104217974](UnityShader入门精要.assets\image-20210718104217974.png)
4. 例子：![image-20210718104441350](UnityShader入门精要.assets\image-20210718104441350.png)
5. 属性的访问：需要在CG代码片中定义和这些属性类型相匹配的变量。但是即使我们不在Properties中声明这些属性，也可以在CG代码中定义变量。此时可以通过脚本向Shader中传递这些属性。

#### 3.3.3 Sub Shader

**概述：**

1. 定义：一个Sub Shader表示这个着色器的一种实现，加载Shader时，Unity会扫描所有的SubShader语义块，然后选择第一个能够在目标平台上运行的SubShader，如果都不支持，会使用Fallback指定的。
2. 原因：不同显卡具有不同能力，所以希望在旧的显卡上使用复杂的较低的着色器，而在高级显卡上使用计算复杂度较高的着色器。
3. 语义块：![image-20210718105300869](UnityShader入门精要.assets\image-20210718105300869.png)
4. Pass：一个Pass定义了一次完整的渲染流程，pass数目过多，会造成渲染性能下降。

**状态设置：**

1. ShaderLab提供了一系列渲染状态的设置指令，这些指令可以设置显卡的各种状态。
2. 在SubShader中设置了状态时，会应用到所有的Pass。也可以在Pass中单独进行设置
3. 常见的渲染状态设置：![image-20210718110301324](UnityShader入门精要.assets\image-20210718110301324.png)

**SubShader标签：**

1. 标签（Tags）是一个键值对，键和值都是字符串类型。
2. 用来告诉渲染引擎：所在SubShader希望怎样以及何时渲染这个对象 ？？？？有点抽象
3. 结构：![image-20210718110511861](UnityShader入门精要.assets\image-20210718110511861.png)
4. 标签类型：这些标签仅可以在SubShader中声明，而不能再Pass中使用。因为标签类型不同![image-20210718110531966](UnityShader入门精要.assets\image-20210718110531966.png)

**Pass语义块：**

1. 包含的语义：![image-20210718110917083](UnityShader入门精要.assets\image-20210718110917083.png)
2. 名字：![image-20210718111006019](UnityShader入门精要.assets\image-20210718111006019.png)
3. 使用名称：![image-20210718111137797](UnityShader入门精要.assets\image-20210718111137797.png)
4. 设置渲染状态：SubShader的状态设置使用于Pass。Pass中还可以使用固定管线的着色器命令。
5. Pass中的标签：不同于Subshader![image-20210718111249221](UnityShader入门精要.assets\image-20210718111249221.png)
6. 特殊的Pass，以便进行代码复用或实现更复杂的效果
   * UsePass：如上面提到的，使用该命令来复用其他Unity Shader的Pass
   * GrabPass：该Pass负责抓取屏幕并将结果存储在一张纹理中，以便用于后续的Pass处理。

#### 3.3.4 Fallback

1. 紧跟在SubShader语义块后面。如果所有的SubShader在这显卡上都不能运行，就使用这个。
2. ![image-20210718111622329](UnityShader入门精要.assets\image-20210718111622329.png)
3. ![image-20210718111634801](UnityShader入门精要.assets\image-20210718111634801.png)

### 3.4 Unity Shader的形式

着色器的代码，可以写在SubShader语义块(表面着色器)中，也可以写在Pass语义块中(顶点\片元着色器)。

着色器代码的位置：![image-20210718214652192](UnityShader入门精要.assets\image-20210718214652192.png)

#### 3.4.1 表面着色器

1. Unity自己创作的一种着色器代码类型，可以理解为Unity对顶点\片元着色器的更高一层的抽象。
2. 本质上和顶点\片元着色器是一样的，Unity在背后仍旧把它转换成对应的顶点\片元着色器。
3. Unity为我们处理了很多光照细节。
4. 实例：![image-20210718214950819](UnityShader入门精要.assets\image-20210718214950819.png)
5. 代码在CGPROGRAM和ENDCG之间，使用CG\HLSL(经Unity封装后的，和标准的有细微的不同)编写。
6. 表面着色器不需要关系有多少个Pass、每个Pass如何渲染，Unity会在背后做好这些事。

#### 3.4.2 顶点\片元着色器

1. 也需要定义在CGPROGRAM和ENDCG之间
2. 写在Pass语义块内，而非SubShader内，原因是，每个Pass需要自定义需要使用的Shader代码。

#### 3.4.3 固定函数着色器

1. 对于一些旧的，不支持可编程管线着色器的设备(其GPU仅支持DirectX 7.0、OpenGL 1.5)使用。
2. 实例：![image-20210718220939627](UnityShader入门精要.assets\image-20210718220939627.png)
3. 被定义在Pass语义块中，但只是一些渲染设置。
4. 这种管线的编程方式已经逐渐被抛弃。

#### 3.4.4 选择哪种Unity Shader形式

1. 除非有明确需求必须使用固定函数着色器，否则使用可编程
2. 需要和各种光源打交道，使用表面着色器，但需要小心在移动平台的性能表现。
3. 需要的光照数目少，使用顶点\片元着色器。
4. 有很多自定义的渲染效果，选择顶点\片元着色器。

### 3.6 答疑解惑

#### 3.6.1 Unity Shader != 真正的Shader

1. Unity Shader中，可以在同一个文件包含需要的顶点着色器和片元着色器代码。
2. Unity Shader中，可以通过一行特定的指令完成一些渲染设置（开启混合、深度测试等）
3. Unity Shader中，可以在特定语句块声明一些属性，依靠材质来方便地改变这些属性，还提供了模型自带数据的访问方法，不需要开发者自行编码来传给着色器
4. Unity Shader中，可以编写的Shader类型和语法都被限制了。

#### 3.6.2 Unity Shader 和 CG\HLSL之间的关系

1. Unity会把CG片段编译成低级语言，如汇编语言等，在导入设置面板上可以查看。
2. 本质上Unity中只存在顶点\片元着色器。
3. Unity会使用不同的编译器把CG片段编译到所有平台，这样切换平台时不用再重新编译。
4. 使用GLSL：代码需要嵌套在GLSLPROGRAM和ENDGLSL之间。用这个意味着发布的目标平台只有MAC OS X、OpenGL ES 2.0或者Linux，而对于PC、Xbox这样仅支持DirectX的平台来说，就相当于放弃了。

### 3.7 扩展阅读

1. [Unity官方文档Manual](http:/docs.unity3d.com/Manual/SL-Reference.html)
2. [NVIDIA提供的CG文档](http://http.developer.nvidia.com/CG/)

## 第4章 学习Shader所需的数学基础



### 4.2 笛卡尔坐标系

1. 左右手坐标系：![image-20210720073423185](UnityShader入门精要.assets\image-20210720073423185.png)

2. 二维坐标系没有左右之分，因为总是可以通过渲染达到一致。
3. 旋转正方向![image-20210720073517552](UnityShader入门精要.assets\image-20210720073517552.png)
4. Unity的模型空间使用的是左手坐标系![image-20210720073605320](UnityShader入门精要.assets\image-20210720073605320.png)
5. Unity的摄像机观察空间使用的是右手坐标系：![image-20210720073620296](UnityShader入门精要.assets\image-20210720073620296.png)
6. 练习题：观察空间下，球体坐标为（0,0,-10）,摄像机的模型空间(相当于以摄像机为坐标原点)下(0,0,10)。   前提是：两种坐标系X轴朝向相同。![image-20210720073710440](UnityShader入门精要.assets\image-20210720073710440.png)

### 4.3 点和矢量

向量在游戏开发中的应用：[1](https://www.cnblogs.com/davidsheh/p/5246213.html)，[2](https://www.cnblogs.com/davidsheh/p/5353304.html),   [3](https://www.cnblogs.com/davidsheh/p/5370325.html)

点：表示n维空间的一个位置。

矢量：指n维空间中一种包含了模(magnitude)和方向的有向线段。比如速度（这辆车的速度是向南80km/h,向南表示方向，80km/h表示模），通常被用于表示相对于某个点的偏移。

标量：只有模，没有方向。

#### 4.3.1 点和矢量的区别

总结：点是一个没有大小之分的空间中的位置，而矢量是一个有模和方向但没有位置的量。

1. 表示偏移时：矢量的尾是一个位置，那么矢量的头就可以表示另一个位置了。此时两个点相减就是这个矢量，也就是偏移。
2. 但一个矢量的尾固定在坐标系原点，那么这个矢量的表示就和点的表示重合。
3. 因此也可以说，任何一个点都可以表示成一个从原点出发的矢量。
4. 后续将用于表示方向的矢量称为方向矢量。

#### 4.3.2 矢量运算

**矢量和标量的乘除法**

1. 乘法,只需要把矢量的每个分量和标量相乘：![image-20210720215434998](UnityShader入门精要.assets\image-20210720215434998.png)
2. 除法：把矢量的每个分量除以标量：![image-20210720215555480](UnityShader入门精要.assets\image-20210720215555480.png)
3. 乘法，矢量和标量的位置可以互换，而除法，只能是矢量被标量除，反之则是没有意义。

**矢量的加法和减法**

1. 就是每个标量相加或者相减：![image-20210720215747728](UnityShader入门精要.assets\image-20210720215747728.png)
2. 加法的几何意义：相当于从一个起点进行了一个偏移位置a，然后进行了一个位置偏移b，相当于进行了一个a+b的位置偏移。
3. 减法：a-b相当于是a点到b点的位移。得到的矢量求模就算出了a到b的距离。
4. 加减法图示：![image-20210720220343831](UnityShader入门精要.assets\image-20210720220343831.png)

**矢量的模**

1. 表示：在矢量两旁分别加上一条垂直线。![image-20210720220928158](UnityShader入门精要.assets\image-20210720220928158.png)
2. 对于二维定理：其实就是使用了勾股定理。斜边的长度就是矢量的模。所以代码里面一些比较时都不直接比较模，因为要开平方。

**单位矢量**

1. 单位矢量指：模为1的矢量，也称为被归一化的矢量(normalized vector)。过程就叫归一化。
2. 给定任何非零矢量v，可以计算单位矢量。![image-20210720221328366](UnityShader入门精要.assets\image-20210720221328366.png)
3. 从二维空间来说，画一个单位圆，单位矢量就是所有从圆心触发，到达球面的矢量。

**矢量的点积**：内积

1. 表示，公式一：![image-20210720221644910](UnityShader入门精要.assets\image-20210720221644910.png)
2. 几何意义：投影，当a是单位矢量时，a.b 就是 b在a方向上的有符号的投影，有可能是负数，如果a和b的方向相反(夹角大于90)，那么结果就小于0.
3. 矢量的点积满足交换律：a.b = b.a
4. 矢量的点积可结合矢量的加法和减法。
5. 矢量和本身进行点积的结果，是该矢量的模的平方。![image-20210721224048792](UnityShader入门精要.assets\image-20210721224048792.png)
6. 对点积中其中一个矢量进行缩放的结果，相当于对最后的点积结果进行缩放。
7. 投影根据夹角的符号：![image-20210722075430113](UnityShader入门精要.assets\image-20210722075430113.png)
8. 公式2：a和b点积与夹角的关系![image-20210722075955973](UnityShader入门精要.assets\image-20210722075955973.png)，![image-20210722080023836](UnityShader入门精要.assets\image-20210722080023836.png)
9. 根据点积计算夹角：![image-20210722080156238](UnityShader入门精要.assets\image-20210722080156238.png)

**矢量的叉积**：外积

1. 叉积运算公式：![image-20210722080304637](UnityShader入门精要.assets\image-20210722080304637.png)
2. 不满足交换律，满足反交换律：a x b = -（b x a）
3. 不满足结合律：(a×b)×c ≠ a×(b×c)
4. 几何意义：两个矢量的叉积的结果，是一个同时垂直于这两个矢量的新矢量。
5. 新矢量的模：|a×b| = |a||b|sinθ   ，这和计算四边形的面积是一样的
6. 四边形面积(底*高)：A = |b|h = |b|(|a|sinθ) = |a||b|sinθ = |a×b|
7. a X b 得到 0向量。模为0.
8. 叉积常见的一个应用：计算垂直于一个平面、三角形的矢量。也可以用于判断三角面片的朝向。



### 4.4 矩阵

#### 4.4.1 描述

英文名：matrix，在三维数学中，通常使用矩阵来进行变换，一个矩阵可以把一个矢量从一个坐标空间转换到另一个坐标空间。比如顶点着色器，需要把顶点坐标从模型空间变换到齐次裁剪坐标系。

矩阵是由m X n个标量组成的长方形数组。有行和列之分。

列矩阵：n X 1 的矩阵  ， 行矩阵：1 X n的行矩阵。

#### 4.4.3 矩阵运算

**矩阵和标量的乘法**

1. 矩阵的每个元素和标量相乘。

**矩阵和矩阵的乘法**

1. 结果：是一个新的矩阵。
2. 可以相乘的前提条件：第一个矩阵的列数必须和第二个矩阵的行数相同。
3. 一个r X n的矩阵和一个 n X c 的矩阵相乘，结果是一个 r X c大小的矩阵。
4. 计算公式：Cij 表示结果矩阵的某一个元素，就是A中的第i行和B中的第j列，把他们对应的元素相乘后，再加起来：![image-20210723081041465](UnityShader入门精要.assets\image-20210723081041465.png)
5. 不满足交换律。
6. 满足结合律

**特殊矩阵**

1. 方块矩阵：简称方阵，指那些行和列数目相等的矩阵。方阵的**对角元素**是指行号和列号相等的元素。如果一个矩阵除了对角元素外的元素都为0，那么这个矩阵叫**对角矩阵**。
2. 单位矩阵：对角元素都为1的对角矩阵叫做单位矩阵
3. 转置矩阵，即转置运算。一个矩阵的转置矩阵表示为：原矩阵的第i行变成第j列，第j列变成第i行。数学公式：![image-20210725170652497](UnityShader入门精要.assets\image-20210725170652497.png)
4. 逆矩阵：方阵 x 方阵的逆矩阵  将会得到一个单位矩阵。![image-20210725171012730](UnityShader入门精要.assets\image-20210725171012730.png)
   * 并非所有矩阵都有对应的逆矩阵。
   * 如果一个矩阵有对应的逆矩阵，则这个矩阵是可逆的，或者非奇异的。
   * 一个矩阵是否可逆：如果一个矩阵的**行列式**不为0，那么他就是可逆的。
   * 性质一：逆矩阵的逆矩阵就是原矩阵本身。
   * 性质二：单位矩阵的逆矩阵是它本身。
   * 性质三：转置矩阵的逆矩阵是逆矩阵的转置。
   * 性质四：矩阵串接相乘后的逆矩阵等于反向串接各个矩阵的逆矩阵。
   * 逆矩阵的几何意义：一个矩阵表示一个变换，而逆矩阵允许我们还原这个变换。比如使用变换矩阵M对矢量v进行一次变换，然后在使用他的逆矩阵M-1进行另一次变换，那么我们会得到原来的矢量。
5. 正交矩阵：如果一个方阵M和他的**转置矩阵**的乘积是单位矩阵的话，我们就说这个矩阵是正交的。

#### 4.4.5 行矩阵还是列矩阵

1. 矢量表示为行矩阵或者列矩阵去乘以另一个矩阵M，得到的结果是不同的。
2. 在Unity中，常规做法是把矢量方阵矩阵的右侧，即把矢量转换成列矩阵来进行运算。矩阵乘法通常都是右乘。
3. ？？？？？

### 4.5 矩阵的几何意义：变换

#### 4.5.1 什么是变换

1. 指把一些数据，如点、方向矢量甚至是颜色等，通过某种方式进行转换的过程。
2. 后面就是将怎么使用一个矩阵乘法，来表示一个矢量(转换成四维矢量，也是一个列矩阵)进行平移旋转缩放这些变换。

**线性变换：**

1. 指那些可以保留矢量加和标量乘的变换。
2. 数学公式表示：![image-20210727211420059](UnityShader入门精要.assets\image-20210727211420059.png)
3. 缩放，旋转、错切、镜像、正交投影等都是线性变换。
4. 对一个三维矢量进行线性变换，那么一个3X3的矩阵就可以表示所有的线性变换。

**平移变换：**例如 f(x) = x + (1,2,3)

**仿射变换：**

1. 合并线性变换和平移变换的变换类型
2. 可以使用一个4X4的矩阵来表示，为此，需要把矢量扩展到思维空间下，这就是齐次坐标空间。

#### 4.5.2 齐次坐标

由于要使用4X4的矩阵来表示平移操作。所以也要把原来的三维矢量转换成四维矢量，也就是齐次坐标（这里齐次坐标将泛指四维齐次坐标）。

**三维转换四维：**

1. 对于一个点：把其w分量设为1.  所以对一个点进行变换时，平移、旋转、缩放都会施加于该点。
2. 对于方向矢量：把其w分量设为0. 所以对一个方向矢量变换时，平移的效果会被忽略

#### 4.5.3 分解基础变换矩阵

1. 可以使用一个4x4矩阵来表示平移旋转和缩放。
2. 把表示纯平移、纯旋转、纯缩放的变换矩阵叫做基础变换矩阵。
3. 共同点，可以把一个基础变换矩阵分解成4个组成部分：![image-20210727214106654](UnityShader入门精要.assets\image-20210727214106654.png)
4. M3x3用于表示旋转和缩放。
5. T3x1用于表示平移
6. 01x3是零矩阵，即 = [0 0 0]
7. 右下角的元素就是标量1

#### 4.5.4 平移矩阵

![image-20210727214443865](UnityShader入门精要.assets\image-20210727214443865.png)

#### 4.5.5 缩放矩阵

![image-20210727214511544](UnityShader入门精要.assets\image-20210727214511544.png)



#### 4.5.6 旋转矩阵

![image-20210727214535439](UnityShader入门精要.assets\image-20210727214535439.png)

#### 4.5.7 复合矩阵

1. ![image-20210727214622902](UnityShader入门精要.assets\image-20210727214622902.png)
2. 约定变换的顺序是先缩放，在旋转，最后平移，因为矩阵的乘法不满足交换律，因此不同的乘法顺序得到的结果不一样。

### 4.6 坐标空间

#### 4.6.1 为什么使用这么多坐标系

因为一些概念只有在特定的坐标空间下才有意义，才更容易理解。

#### 4.6.2 坐标空间的变换

1. 定义一个坐标空间，必须指明其原点位置和3个坐标轴的方向。而这些数值实际上是相对于另一个坐标空间。
2. 所有空间都是相对的。
3. 坐标空间会形成一个层次结构，每个坐标空间都是另一个坐标空间的子空间，反过来，每个空间都有一个父空间，坐标空间的变换实际上就是在父空间和子空间之间对点和矢量进行变换。
4. 变换公式：![image-20210729213803204](UnityShader入门精要.assets\image-20210729213803204.png)
5. 转换：![image-20210729215030564](UnityShader入门精要.assets\image-20210729215030564.png)
6. 上诉把最后那个公式进行一些推到就就得到了一个父子空间之间转换的矩阵。其实和数学公式差不多，就通过基本概念(这里是原点的移动)，设x，设y得出一个基本公式，然后一推导。

#### 4.6.3 顶点的坐标空间变换过程

从模型空间，最后变换到屏幕空间得到真正的屏幕像素坐标的空间变换过程。

例子：农场游戏中，妞妞的鼻子是怎么被画到屏幕上的。![image-20210729215331396](UnityShader入门精要.assets\image-20210729215331396.png)

#### 4.6.4 模型空间

1. 也称为对象空间或局部空间。
2. 模型空间中的方向概念，“前(forward)”、“后(back)”、"上(up)"等，称为自然方向。
3. Unity在模型空间中使用的是左手坐标系，因此+x轴，+y轴，+z轴分别对应模型的右、上、前。
4. 假设妞妞的鼻子的模型空间的位置是(0,2,4),齐次坐标下的表示为(0,2,4,1). w分量为1，因为是点。

#### 4.6.5 世界空间

1. 建立了我们所关系的最大的空间。在农场游戏中，农场就是世界空间。我们不关心农场在哪儿，因为在游戏中，农场就是最大的空间概念。
2. 世界空间可以用于描述绝对位置。绝对位置是指在世界坐标系中的位置。
3. Unity中，世界坐标同样使用了左手坐标系。
4. 模型变换：将模型空间变换到世界空间。
5. 根据妞妞根节点的参数，可以得到妞妞的在世界坐标中的缩放，旋转和平移，就可以得出模型至世界的变换矩阵，然后带入鼻子的模型空间的坐标，就可以计算出鼻子的世界空间坐标。
6. Unity中应该有接口可以获取这个矩阵，或者接口可以直接算出来坐标。

#### 4.6.6 观察空间

1. 也称为摄像机空间。观察空间可以认为是模型空间的一个特例---在所有的模型中有一个非常特殊的模型，即摄像机。
2. 观察空间中，摄像机位于原点，坐标轴的选择可以是任意的。unity中，+x指右方，+y指上方，+z指后方（之前的模型空间和世界空间的+z都是指前方，因为之前的都是左手坐标系，而观察空间使用的是右手坐标系。这是符合OpenGL传统的）。
3. 左右手坐标系的差异，很少对我们编程造成影响，因为Unity做了很多底层工作，包括坐标转换，但是如果自行使用Camera.cameraToWorldMartix等接口就需要小心这些差异。
4. 世界空间到观察空间的变换叫做观察变换。
5. 方法一：使用4.6.2节的方法，构建从观察变换到世界的变换矩阵，在求逆矩阵。就可以拿到世界至观察矩阵
6. 方法二：想象平移整个观察空间，让摄像机原点位于世界坐标的原点，坐标轴与世界空间中坐标轴重合，这样就直接得到了世界至观察矩阵。、

#### 4.6.7 裁剪空间

1. 从观察空间转换到裁剪空间（也叫齐次裁剪空间）中的矩阵叫做裁剪矩阵，也叫投影矩阵。
2. 裁剪空间的目标是方便地对渲染图元进行裁剪，这块空间是有视椎体决定的。
3. 视椎体是空间中的一块区域，由六个平面包围，这些平面称为裁剪平面。视椎体有两种类型，涉及两种投影方式，正交投影和透视投影。
4. 投影矩阵有两个目的
   * 为投影做准备，这里没有进行真正的投影工作，而只是准备，真正的投影发生在后面的齐次出除法中。
   * 对x、y、z分量进行缩放。直接使用视椎体的6个裁剪平面来进行裁剪会比较麻烦，而经过投影矩阵的缩放后，可以直接使用w分量作为一个范围值，如果x、y、z分量都位于这个范围内，则该顶点位于裁剪空间内

**透视投影**

![image-20210803212040315](UnityShader入门精要.assets\image-20210803212040315.png)

**正交投影**

![image-20210803212119434](UnityShader入门精要.assets\image-20210803212119434.png)

#### 4.6.8 屏幕空间

经过投影矩阵的变换后，我们可以进行裁剪操作，裁剪工作完成后，就进行真正的投影，即把视椎体投影到屏幕空间。这一步将得到像素位置。

**齐次除法**(homogeneous division),也称为透视除法，就是使用w分量去除以x、y、z分量。OpenGL中这一步得到的坐标叫归一化的设备坐标(Normalized Device Coordinates，NDC)。经过这一步坐标就变换到一个立方体内。范围是[-1,1]。而对于正交投影，这一步之后没有变化，因为正交投影的视椎体本来就是一个立方体。

**长方体映射屏幕**：clip->裁剪空间的坐标。pixelWidth指屏幕像素宽度。![image-20210808203258404](UnityShader入门精要.assets\image-20210808203258404.png)

#### 4.6.9 总结

下图总结了一个顶点如何从模型空间变换到屏幕坐标的过程。![image-20210808204110107](UnityShader入门精要.assets\image-20210808204110107.png)

### 4.7 法线变换

法线也被称为法矢量。是模型的一个顶点携带的额外信息的一种。变换模型时，不仅需要变换顶点，也需要变换顶点法线。

切线也被称为法矢量，也是额外信息的一种，通常与纹理空间对齐，与法线方向垂直。

法线的顶点变换，由于需要与切线保持垂直，所以需要一些特殊的处理。

### 4.8 Unity Shader的内置变量

Unity提供了很多内置参数，我们不在需要自己手动计算一些值，这些变量可以在UnityShaderVariables.cginc文件中找到定义和说明。

#### 4.8.1 变换矩阵 Unity5.2

![image-20210808205147816](UnityShader入门精要.assets\image-20210808205147816.png)

#### 4.8.2 摄像机和屏幕参数

Unity提供了一些内置变量来让我们访问当前正在渲染的摄像机的参数信息。

![image-20210808205439668](UnityShader入门精要.assets\image-20210808205439668.png)

### 4.9 答疑解惑

## 第五章 开始Unity Shader学习之旅

### 5.2 一个简单的顶点/片元着色器

1. 指定着色器函数：#pragma vertex vert：片元着色器的函数代码在ver方法中。
2. 着色器的函数声明不仅要指定输入输出的数据类型(float4等)，还要指定输入输出的数据意义(比如POSITION：模型空间顶点位置   SV_POSITION:裁剪空间顶点位置)
3. 输入输出的参数也可以定义一个结构体，实现多参数输入与输出，结构体内部的变量同样声明数据类型和数据意义即可。
4. Unity支持的语义有：POSITION,TANGENT,NORMAL,TEXCOORD0,TEXCOORD1,TEXCOORD2,COLOR等。
5. 上诉语义确定的数据来源：一些是由Mesh Render提供的。调用Draw Call的时候，MeshRender会把它负责渲染的模型数据发送给Unity Shader。
6. 顶点着色器与片元着色器的通信，定义一个结构体作为顶点着色器的输出，片元着色器的输入，里面定义一个color，在顶点着色器中设置，那么在片元着色器中就可以使用。
7. 使用属性：在Properties中定义一个属性，然后在CG代码中，定义一个与属性名称和类型都匹配的变量，就可以直接使用。![image-20210815110815629](UnityShader入门精要.assets\image-20210815110815629.png)

### 5.3 Unity提供的内置文件和变量

Unity提供了很多内置文件，这些文件包含了很多提前定义的函数、变量和宏等。

1. 包含文件：如#include "UnityCG.cginc" 。包含后就可使用Unity为我们提供的变量和帮助函数。
2. 这些文件可以在Unity的[官方网站](https://unity.cn/releases)选择Unity版本，在下载的下拉框选择BuildInShader来下载。
3. 一些文件是自动包含的，因此不用Include也可以直接使用。
4. 常用的包含文件。![image-20210815112523338](UnityShader入门精要.assets\image-20210815112523338.png)
5. UnityCG.cginc是最长接触的一个包含文件。去文件查看下面结构体中的声明，可以**快速理解Unity中一些内置变量的工作原理**。![image-20210815112614436](UnityShader入门精要.assets\image-20210815112614436.png)![image-20210815112644032](UnityShader入门精要.assets\image-20210815112644032.png)
6. UnityShaderVariables.cginc中提供了用于访问时间、光照、雾效和环境光等目的的变量，Lighting.cginc、AutoLight.cfinc中有很多光照有关的内置变量。

### 5.4 Unity提供的CG/HLSL语义

1. 前面看见的SV_POSITION、POSITION等用来指定输入输出参数意义的字符串，就是语义。
2. 前面这些都是CG\HLSL提供的语义。Unity并不支持所有的语义。这些语义告诉Shader从哪里读取数据，以及把数据输出到哪里。
3. 一些变量通常没有特殊含义，比如上面使用COLOR0描述color，color本身存储了什么，Shader流水线并不关心。这种应该是CG定义了这个语义，但是没有赋予这个语义特殊的意义，使用者可以通过这个语义来指定一些自定义数据，然后输入和输出。比如顶点着色器输出一个COLOR0，片元着色器就可以拿到，然后进行使用。使用者自己定义意义。
4. Unity为了方便对模型数据的传输，对一些语义进行了特别的含义规定，比如在在顶点着色器的输入结构中，使用TEXCOORD0来指定把模型的第一组纹理坐标填充到变量中。这语义应该是CG没有赋予意义，但是UNity赋予了意义。
5. 系统数值语义，DirectX10以后出现：这类语义以SV开头。这些语义在渲染流水线中有特殊含义。
6. SV_POSITION，POSITION在不同的Shader都用来修饰顶点着色器的输出，绝大多数平台上，他们等价，但有些平台就只能使用SV_POSITION来修饰。
7. ![image-20210815194039586](UnityShader入门精要.assets\image-20210815194039586.png)
8. ![image-20210815193920634](UnityShader入门精要.assets\image-20210815193920634.png)
9. ![image-20210815193943417](UnityShader入门精要.assets\image-20210815193943417.png)



### 5.5程序员的烦恼：Debug

1. 使用假彩色图像，把需要调试的变量映射到[0,1]之间，然后作为颜色输出到屏幕上，然后通过显示的像素颜色来判断这个值是否正确。很原始的一种方式。
2. Visual Studio：Graphics Debugger，查看Unity官方文档，使用Vs对DirectX11的shader调试。
3. 最新：帧调试器：Unity里面：Window/Analize/FrameDebuger. 可以查看渲染该帧时进行的各种**渲染事件**。

### 5.6 渲染平台的差异

Unity在背后处理了绝大部分的差异，但有些时候需要自己处理

1. OpenGL和DirectX的屏幕空间坐标的差异。OpenGl中(0,0)表示屏幕左下角，DirectX中(0,0)表示屏幕左上角。当我们要使用渲染到纹理技术，把屏幕图像渲染到一张渲染纹理中时，Unity就会为我们处理这个差异，当在DirectX上使用这技术时，Unity会为我们翻转屏幕图像纹理。但当我们开启了抗锯齿时，则不会。、
2. Shader语法差异：DirectX9/11可能对Shader的语义更加严格。比如float4的构造函数，在max平台下只传入一个参数没问题，而在windows平台下就会报错。
3. SHader的语义差异：如SV_POSITION和POSITION，在一些平台等价，而在另外一些平台不等价。所以尽量保证使用SV_POSITION描述顶点着色器输出的顶点位置，SV_Tartget来描述片元着色器的输出颜色。
4. 其他差异：可以在[unity官方文档](https://docs.unity3d.com/Manual/SL-PlatformDifferences.html)查看。

### 5.7 Shader整洁之道

**float、half还是fixed**

1. 使用CG/HLSL来编写UnityShader代码时，有这三种精度的数值类型。
2. ![image-20210818193349097](UnityShader入门精要.assets\image-20210818193349097.png)
3. 在PC上，桌面GPU会把所有计算都按照最高的浮点精度进行计算，也就是说，在PC上这三种类型是等价的。
4. 在移动平台，则的确会有不同的精度范围，而且运算速度也有差异，所以要在移动平台验证我们的Shader。
5. fixed只在一些旧的移动平台有用，大多数现代的GPU，内部把fixed和half当成同等精度对待。

**规范语法**

1. DirectX对Shader的语义有更加严格的要求，因此要使用更严格的语法。比如使用和变量类型相匹配的参数数目来初始化变量。

**避免不必要的计算**

1. 大量计算导致的错误，由于过多运算，使得需要的临时寄存器数目或指令数目超过了当前可支持的数目：![image-20210818193804609](UnityShader入门精要.assets\image-20210818193804609.png)
2. 不同的ShaderTarget、不同的着色器阶段，可使用的临时寄存器和指令数目是不同的。
3. ![image-20210818193935273](UnityShader入门精要.assets\image-20210818193935273.png)
4. Shader Model：有微软提出的一套规范，他们决定了Shader中各个特性和能力。等级越高，能力越大。

**慎用分支和循环**

1. GPU使用不同于CPU的技术来实现分支，在最坏的情况，花在一个分支语句的时间相当于运行所有分支的时间。
2. 会降低GPU的并行处理操作，性能会成倍下降。
3. 不可避免分支时，分支判断语句中使用的条件变量最好是常数。分支中包含的指令数尽量少，分支的嵌套层数尽量少。

**不要除以0**



## 第六章 Unity中的基础光照

从宏观上来说，渲染包含了两大部分：决定一个像素的可见性，决定这个像素上的光照计算。而光照模型就是用于决定在一个像素上进行怎样的光照计算。

### 6.1 我们是如何看到这个世界的

**模拟真实光照环境生成图形要考虑3种物理现象**

1. 光线从光源中被发射出来
2. 光线和场景中的一些物体相交：一些光线被物体吸收了，另一些被散射到其他方向。
3. 最后，摄像机吸收了一些光，产生了一张图像。

**光源**

1. 在实时渲染中，通常把光源当成一个没有体积的点，用l来表示他的方向。
2. 光学中，使用辐照度来量化光。对于平行光，辐照度可以通过计算在垂直于l的单位面积上单位时间内穿过的能量来得到。
3. 计算物体表面的辐照度：使用光源方向l和表面法线n之间的夹角的余弦值来得到。

**吸收和散射**

1. 光线与物体相交的结果：散射和吸收。散射只改变光线的方向，吸收只改变光线的密度和颜色。
2. 散射有两种方向：一种被散射到物体内部，称为折射或透射。另一种散射到外部，称为反射。
3. 为了区分两种不同的散射方向，在光照模型中使用了不同的部分来计算他们
   * 高光反射：表示物体表面是如何反射光线的
   * 漫反射：表示有多少光线会被折射、吸收和散射处表面。
   * 根据入射光线的数量和方向，可以计算出射光线的数量和方向，使用出射度来描述它。
4. 辐照度和出射度之间满足线性关系，比值就是材质的漫反射和高光反射属性。

**着色**

1. 指根据材质属性(如漫反射属性)、光源信息（如光源方向，辐照度），使用一个等式去计算沿着某个观察方向的出射度的过程。这个等式称为**光照模型**。
2. 不同的光照模型有不同的目的：例如一些用于描述粗糙的物体表面，一些用于描述金属表面。

**BRDF光照模型**

1. 当给定模型表面上的一个点时，BRDF包含了对该点外观的完整描述。
2. 当给定入射光线的方向和辐照度后，BRDF可以给出在某个出射方向上的光照能量描述。
3. 邓恩著作《3d数学技术：图形与游戏开发》名言：“计算机图形学的第一定律：如果它看起来是对的，那么他就是对的”。

### 6.2 标准光照模型

裴祥风提出的基本理念：标准光照只关心直接光照，也就是那些直接从光源发射出来射到物体表面后，经过表面一次反射直接进入摄像机的光线。

基本方法：把进入到摄像机的光线分成4个部分，每个部分使用一种方法来计算它的贡献度。

1. 自发光：missive， 描述给定一个方向时，一个表面本身会向该方向发射多少辐射量。但是如果没有使用全局光照，这些自发光的表面并不会真的照亮周围的物体，而是它本身看起来更亮。
2. 高光发射：specular，描述当光线从光源照射到模型表面，该表面会在完全镜面发射方向散射多少辐射量。
3. 漫反射：diffuse，描述当光线从光源照射到模型表面，该表面会向每个方向散射多少辐射量。
4. 环境光：ambient，描述其他所有的间接光照。

#### 6.1.1 环境光

间接光照：指光线通常会在多个物体之间反射，最后进入到摄像机。

在标准光照模型中，使用环境光来模拟间接光照。环境光的计算非常简单，通常是一个全局变量，即场景中的所有物体都是用这个环境光。

#### 6.2.2 自发光

1. 光线可以直接由光源发射进入摄像机，不需要经过任何物体的反射。
2. 计算很简单，就是直接使用改材质的自发光颜色。在实时渲染中，自发光的表面往往并不会照亮周围的表面。也就是说，这个物体并不会被当做一个光源。
3. 但是Unity5引入的新的全局光照系统可以模拟这类自发光物体对周围物体的影响。

#### 6.2.3 漫反射

1. 用于对那些被物体表面随机散射到各个方向的辐射度进行建模的。
2. 视角的位置是不重要的，因为反射的完全随机的。但是入射光线的角度很重要
3. 漫反射光照符合兰伯特定律(Lambert's law)，反射光线的强度与表面法线和光源方向之间的夹角的余弦值成正比。

#### 6.2.4 高光反射

1. 是一种经验模型，不完全符合真实世界中的高光反射现象。
2. 用于计算那些颜色完全镜面反射方向被反射的光线，可以让物体看起来是有光泽的。
3. 计算：比较复杂，就不看了。

#### 6.2.5 逐像素还是逐顶点

上面基本光照模型使用的数学公式，在哪里计算光照模型呢？

1. 片元着色器中，也称为逐像素光照。以每个像素为基础，得到它的法线(可能是插值得到)，然后进行计算。这种在面片之间对顶点法线进行插值的技术称为Phong着色。
2. 顶点着色器中，称为逐顶点光照。也叫高洛德着色。在每个顶点上计算光照，然后在渲染图元内部进行线性插值，最后输出成像素颜色。因为依赖线性插值，所以当光照模型中有非线性计算时，就会出问题。

#### 6.2.6 总结

虽然标准光照模型仅仅是一个经验模型，但由于他的易用性，计算速度和得到的效果都比较好，任然广泛使用。

### 6.3 Unity中的环境光和自发光

Unity场景中的环境光控制：window->Lighting->Ambient Source/Ambient Color/Ambient Intensity

大多数物体是没有自发光特性的，如果计算自发光：只需要在片元着色器输出最后的颜色之前，把材质的自发光颜色添加到输出颜色上即可。

### 6.4 在Unity Shader中实现漫反射光照模型

漫反射计算公式

1. 基本光照模型中漫反射部分的计算公式：![image-20210905210033026](UnityShader入门精要.assets/image-20210905210033026.png)
2. 公式需要四个参数：入射光线的颜色和强度Clight，材质的漫反射系数Mdiffuse，表面法线n，光源方向I。
3. max是防止点积结果为负值，CG提供了这样的函数 saturate(x)（用于将标量或矢量截取在[0,1]范围内）。

Unity中实现漫反射

1. 学习工程中：Chapter6,Scene_6_4,  Shader:DiffuseVertexLevel
2. **_Diffuse.rgb 是一个数值吗，表示什么**，\_LightColor0.rgb*\_Diffuse.rgb是什么算式

### 6.5 在Unity Shader中实现高光反射光照模型

高光发射公式

1. 高光反射的计算公式：![image-20210911112413442](UnityShader入门精要.assets/image-20210911112413442.png)
2. 需要四个参数：入射光线的颜色和强度Clight，材质的漫反射系数Mspecular，视角方向V以及反射方向r。反射方向r可以有表面法线n和光源方向I计算而得：CG提供了计算反射方向的函数，reflect(i,n)![image-20210911112604105](UnityShader入门精要.assets/image-20210911112604105.png)
3. ![image-20210911112748226](UnityShader入门精要.assets/image-20210911112748226.png)
4. ![image-20210912085906650](UnityShader入门精要.assets/image-20210912085906650.png)
5. BlinnPhong模型代码：![image-20210912094345180](UnityShader入门精要.assets/image-20210912094345180.png)

### 6.6 召唤神龙：使用Unity 内置的函数

1. 上面计算中需要计算光源方向、视角方向这两个基本信息，而在复杂的光照模型下，那个计算方式是错误的。

## 第七章 基础纹理

1. 纹理的最初目的是用一张图片来控制模型的外观。
2. 使用纹理映射计数，可以把一张图黏在模型表面，逐像素地控制模型的颜色。
3. 美术人员在建模软件中，把纹理映射坐标(定义顶点在纹理中对应得2D坐标，使用二维变量(u,v)来表示)存储在每个顶点上。
4. 纹理大小可以多种多样，纹理坐标的范围通常被归一到[0,1]的范围。但纹理采样时使用的纹理坐标不一定在[0,1]内，受采样方式控制，比如循环采样。
5. 在Unity中，纹理空间符合OpenGL传统，左下角为原点（0,0）

### 7.1 单张纹理

1. 将纹理带入片元着色器的颜色计算：![image-20210912110414667](UnityShader入门精要.assets/image-20210912110414667.png)
2. Filter Mode：决定了由于变换而产生拉伸时采用的滤波模式，Point，Bilinear，Trilinear效果依次提升，但耗费性能依次增大。Point模式会感觉有像素风。

### 7.2 凹凸纹理

目的是使用一张纹理来修改模型表面的法线，以便为模型提供更多的细节，让模型看起来好像是凹凸不平的。

两种主要方式：高度纹理和法线纹理

#### 高度纹理

1. 高度纹理来模拟表面位移，得到一个修改后的法线值，这种方法也称为高度映射
2. 高度图存储的是强度值，表示模型表面局部的海拔高度，颜色越浅表面该位置越向外凸起。
3. 好处是非常只管，缺点是更加复杂，计算时不能直接得到表面法线，而是需要由像素的灰度值计算。
4. 高度图通常和法线映射一起使用，通常会使用法线映射来修改光照。

#### 法线纹理

1. 使用法线纹理来直接存储表面法线，又称为法线映射。
2. 分为模型空间的法线纹理和切线空间的法线纹理。切线空间的优点是自由度很高、可进行UV动画(移动UV坐标来实现一个凹凸移动的效果，在水或者火山熔岩这种物体上经常用到)、可重用，可压缩
3. 大多数时候都是使用的切线空间的法线纹理。纹理看起来没有模型的形状就是切线空间的。

#### 实践

1. 切线空间下的计算：_BumbMap表示法线贴图，\_BumbScale表示凹凸程度。
2. 实际代码有点复杂，**先不看了**
3. 世界空间下的计算：也复杂，**先不看了**
4. **去看看公司里面的Shader**

#### Unity中的法线纹理类型

1. 贴图类型选择NormalMap。因为Unity内部会进行压缩和解压缩。当进行纹理采样时使用的Unity内置的UnpackNormal函数，实际就是针对压缩格式进行正确的采样。
2. CreateFromGrayscale选项：用于从高度图中生成法线纹理的，高度图本身就是一张灰度图。勾选后出现的选项Bumpiness控制凹凸程度，Filtering觉得使用那种凡是计算凹凸成都。



### 7.3 渐变纹理

1. **可以用来实现一些卡通化效果。**

2. ![image-20210912154455661](UnityShader入门精要.assets/image-20210912154455661.png)

   

3. ![image-20210912154536412](UnityShader入门精要.assets/image-20210912154536412.png)

4. 和上面的法线贴图使用都差不多，要不是算出一个颜色乘到diffuse的计算，要不是乘到specular的计算里面。

5. 成品效果可能出现小黑点的话：可能是WrapMode为Repeat时，浮点数精度的原因，改为Clamp就好了。

### 7.4 遮罩纹理

1. 是把遮罩纹理的值乘到specular上面，主要用来控制高光。
2. ![image-20210912160135395](UnityShader入门精要.assets/image-20210912160135395.png)



## 第八章 透明效果



























